現代制御の弱点
従来の現代制御は，状態方程式（計算式）と観測方程式（計算式）を用いるが，これらは雑音に大きく影響を受けてしまう．そのため，不真面目な答え（統計的アプローチ）が必要になることがわかった．
代表値とは何か
代表値については，平均値，中央値，最頻値などがあることは分かっていたため，知ってはいたが，きちんと使いこなせていないことが分かった．
代表値の例として，平均値とは（式）で，中央値はデータを数値の大きさで順に並べて，中央に着たデータの値，最頻値は，データ列中で最も戸数の多い値，最大，最小値は，データの中で最大，最小の値などがある．
しかし，代表値はデータの不可逆圧縮であり，平均値が高いからこちらの方がよいといったことは言ってはいけないことが分かった．
また，最も一般的なばらつきの指標である分散（式）が必要になる．これの正の平方根が標準偏差となるが，必要な理由が，元のデータと単位が同じになり，グラフに書き込めるというからということが分かった．
バイアスやアウトライアといったものは自律ロボットを扱う上では，考える必要があることも分かった．
確率の重要性
定理は乗法定理と加法定理の二つのみ
乗法定理（式）独立の場合（式），加法定理（式）独立の場合（式）．これらの計算は，どのような事象があるか，条件があるかを考える必要がある．そして，空事象，余事象，全事象を計算に利用することも大切ということが分かった．
確率変数とは，事象に数を対応させたものである．これを利用することで，数直線上での確率の分布がわかる確率分布を書くことができることが分かった．例としては，変数が2値だけのベルヌーイ分布や，変数のある範囲で確率が一定となる一様分布などがある．
また，2つ以上の確率変数に対する分布である同時分布があり，周辺化などの計算を利用することが大切ということが分かった．
期待値とは何か
何かを決めたらどれだけ見返りが戻ってくるかを勘ではなく，数値で考えられるためのもの．
期待値（式）．これは事象A,B,C,D,Eが互いに排反で，A~Eでない事象が起こる確率が0と考えた場合．
また，確率変数を使った表記では（式）になる．そして，平均値はPから値を無限に取り出した時の期待値（式）．分散は，Pから値を無限に取り出した時の平均との差の2乗の期待値（式）．
連続値と多変量に対する確率分布
連続値，多変量では離散値に近似して確率分布を求める方法，空間を囲って確率を計算するモンテカルロ法があることが分かった．
確率を区間の幅で割った値が密度で，密度を導入することで確率密度関数を定義できることが分かった．また，2次元の場合は，面積で，3次元の場合は体積で割ることで密度が求められることが分かった．
ガウス分布とは
分布を数式で表す方法として，ガウス分布（式）があり，ガウス分布の形を決めているのは指数部となる．分布と関係ない部分は正規化定数として表記される．また，標準偏差で正規化したマハラノビス距離（式）で指数部の値が決まることが分かった．ガウス分布は，1σ: 約68％，2σ: 約95％，3σ: 約99.7%のデータが収まることが分かった．
多変量ガウス分布は（式），マハラノビス距離は（式）で求められることが分かった．
ベイズの定理
ベイズの定理は（式）となる．また，（式）と表記できる．P(a)は事前分布，P(a|b)は事後分布，P(b|a)は尤度，P(b|a)のaの方を変数として考えたL(a|b)は尤度関数として表せることが分かった．
状態遷移
二つの表現形式があり，状態方程式（式），f: 状態遷移関数で，もう一つが（式），（式）:状態遷移分布となる．二つ目は，抽象的で扱える範囲が広いことが分かった．また，状態遷移の分布が遷移直前の状態の分布だけで決まることをマルコフ性ということも分かった．
線形な状態方程式（式），非線形な状態方程式（式）となる．ガウス分布を使わない方法として，パーティクルをたくさん用意し，状態遷移分布を使って動かす，モンテカルロ法や，空間を格子状に区切り，各講師の確率を計算するヒストグラムフィルタがあることが分かった．
ベイズフィルタ
動きと情報をロボット自身が持つ自己位置の分布である新年分布に変換するもので，ロボットが動いたときは（式）で，情報が得られたときは（式）で表記できることが分かった．
カルマンフィルタ
ガウス分布を利用したベイズフィルタであり，線形の場合の観測方程式（式）となる．観測が信念分布に与える影響力の強さである，カルマンゲインは（式）と表記できる．非線形の場合の観測方程式は（式）となる．
モンテカルロ法を利用したベイズフィルタがパーティクルフィルタであることが分かった．
回帰問題
最小二乗法は，損失関数L=（式）と表記できる．これは，一つの答えしか出さないため，自信のなさが表現できない．そのため，ベイズ線形会期が必要であり（式）と表せられる．
クラスタリング
クラスタリングは，K-means法: データを適当にKこのクラスタに分けて-①，各クラスタの中心を求める-②，各データを最寄りの中心に再割り当て-③，②③を収束するまで繰り返す手法や，EM法: 基本的なモデルを混合ガウス分布として，Mステップ: 尤度が最大となる各クラスタにu1;n, Σ1:n，π1;nを算出，Eステップ: u1:n, Σ1:n, π1:nに基づきデータをクラスタリングする，これらを収束するまで繰り返す手法．そして，強力である混合分布の分布を考える変分推移があることが分かった．